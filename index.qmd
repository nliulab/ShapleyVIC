# ShapleyVIC Introduction {.unnumbered}

Variable importance assessment is important for interpreting machine learning
models. Current practice in interpretable machine learning applications focuses
on explaining the final models that optimize predictive performance. However,
this does not fully address practical needs, where researchers are willing to
consider models that are "good enough" but are easier to understand or
implement. Shapley variable importance cloud (ShapleyVIC) fills this gap by
extending current method to a set of "good models" for comprehensive and robust
assessments. Building on a common theoretical basis (i.e., Shapley values for
variable importance), ShapleyVIC seamlessly complements the widely adopted SHAP
assessments of a single final model to avoid biased inference. Please visit 
[GitHub page](https://github.com/nliulab/ShapleyVIC) for source code.

<div class="figure" style="text-align: center">
<img src="figures/graphical_abstract.jpg" width="70%"/>
</div>

## Usage

As detailed in [Chapter 3](ch2_shapleyvic.qmd) ShapleyVIC analysis of variable 
importance consists of 3 general steps:

1. Training an optimal prediction model (e.g., a logistic regression model).
2. Generating a reasonable number of (e.g., 350) nearly optimal models of the
same model class (e.g., logistic regression).
3. Evaluate Shapley-based variable importance from each nearly optimal model and
pool information for inference.

[Chapter 3](ch2_shapleyvic.qmd) demonstrates ShapleyVIC application for 
binary outcomes, and [Chapter 6](ch5_shapleyvic_ord.qmd) and 
[Chapter 7](ch6_shapleyvic_cont.qmd) provide additional examples for applications 
for ordinal and continuous outcomes, respectively.

ShapleyVIC does not require variable centering or standardization, but requires 
some data checking and pre-processing for stable and smooth processing, which we 
summarize in [Chapter 2](ch1_data.qmd).

The ShapleyVIC-based variable ranking can also be used with the 
[AutoScore framework](https://nliulab.github.io/AutoScore/) to develop clinical 
risk scores for interpretable risk prediction, which we demonstrate in 
[Chapter 4](ch3_autoscore_shapleyvic.qmd) and 
[Chapter 5](ch4_autoscore_shapleyvic_reprod.qmd).

## Installation

The ShapleyVIC framework is now implemented using a [**Python library**](python)
that trains the optimal model, generates nearly optimal models and evaluate
Shapley-based variable importance from such models, and an [**R package**](r)
that pools information across models to generate summary statistics and
visualizations for inference.

### Python library

- **Required:** [Python](https://www.python.org/downloads/) version 3.6
or higher.
    - ***Recommended:*** latest stable release of Python 3.9 or 3.10.
- **Required:** latest version of
[git](https://git-scm.com/book/en/v2/Getting-Started-Installing-Git).

Execute the following command in Terminal/Command Prompt to install the Python
library from GitHub:

- Linux/macOS: 

```{bash, eval=FALSE}
pip install git+"https://github.com/nliulab/ShapleyVIC#egg=ShapleyVIC&subdirectory=python"
```

- Windows:

```{bash, eval=FALSE}
python.exe -m pip install git+"https://github.com/nliulab/ShapleyVIC#egg=ShapleyVIC&subdirectory=python"
```

::: callout-note
- *ShapleyVIC uses [a modified version of the SAGE library (version 0.0.4b1)](https://github.com/nyilin/sage), which avoids occasional stack overflow problems on Windows but does not affect variable importance evaluation.*
:::

### R package

- **Required:** [R](https://cloud.r-project.org/) version 3.5.0 or higher.
    - ***Recommended:*** use latest version of R with 
    [RStudio](https://www.rstudio.com/products/rstudio/download/).

Execute the following command in R/RStudio to install the R package from GitHub:

```{r, eval=FALSE}
if (!require("devtools", quietly = TRUE)) install.packages("devtools")
devtools::install_github("nliulab/ShapleyVIC/r")
```

## Citation

### Core paper

- Ning Y, Ong ME, Chakraborty B, Goldstein BA, Ting DS, Vaughan R, Liu N. [Shapley variable importance cloud for interpretable machine learning](https://doi.org/10.1016/j.patter.2022.100452). *Patterns* 2022; 3: 100452.

### Method extension

- Ning Y, Li S, Ong ME, Xie F, Chakraborty B, Ting DS, Liu N. [A novel interpretable machine learning system to generate clinical risk scores: An application for predicting early mortality or unplanned readmission in a retrospective cohort study](https://doi.org/10.1371/journal.pdig.0000062). *PLOS Digit Health* 2022; 1(6): e0000062.

## Clinical applications

- Deng X, Ning Y, Saffari SE, Xiao B, Niu C, Ng SYE, Chia N, Choi X, Heng DL, Tan YJ, Ng E, Xu Z, Tay KY, Au WL, Ng A, Tan EK, Liu N, and Tan LCS (2023). [Identifying clinical features and blood biomarkers associated with mild cognitive impairment in Parkinson's Disease using machine learning](https://doi.org/10.1111/ene.15785). *European Journal of Neurology*, 00:1â€“9. 

## Contact

- Yilin Ning (Email: yilin.ning@duke-nus.edu.sg)
- Nan Liu (Email: liu.nan@duke-nus.edu.sg)
