[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "",
    "text": "ShapleyVIC Introduction\nVariable importance assessment is important for interpreting machine learning models. Current practice in interpretable machine learning applications focuses on explaining the final models that optimize predictive performance. However, this does not fully address practical needs, where researchers are willing to consider models that are “good enough” but are easier to understand or implement. Shapley variable importance cloud (ShapleyVIC) fills this gap by extending current method to a set of “good models” for comprehensive and robust assessments. Building on a common theoretical basis (i.e., Shapley values for variable importance), ShapleyVIC seamlessly complements the widely adopted SHAP assessments of a single final model to avoid biased inference. Please visit GitHub page for source code."
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "Usage",
    "text": "Usage\nAs detailed in Chapter 3 ShapleyVIC analysis of variable importance consists of 3 general steps:\n\nTraining an optimal prediction model (e.g., a logistic regression model).\nGenerating a reasonable number of (e.g., 350) nearly optimal models of the same model class (e.g., logistic regression).\nEvaluate Shapley-based variable importance from each nearly optimal model and pool information for inference.\n\nChapter 3 demonstrates ShapleyVIC application for binary outcomes, and Chapter 6 and Chapter 7 provide additional examples for applications for ordinal and continuous outcomes, respectively.\nShapleyVIC does not require variable centering or standardization, but requires some data checking and pre-processing for stable and smooth processing, which we summarize in Chapter 2.\nThe ShapleyVIC-based variable ranking can also be used with the AutoScore framework to develop clinical risk scores for interpretable risk prediction, which we demonstrate in Chapter 4 and Chapter 5."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "Installation",
    "text": "Installation\nThe ShapleyVIC framework is now implemented using a Python library that trains the optimal model, generates nearly optimal models and evaluate Shapley-based variable importance from such models, and an R package that pools information across models to generate summary statistics and visualizations for inference.\n\nPython library\n\nRequired: Python version 3.6 or higher.\n\nRecommended: latest stable release of Python 3.9 or 3.10.\n\nRequired: latest version of git.\n\nExecute the following command in Terminal/Command Prompt to install the Python library from GitHub:\n\nLinux/macOS:\n\n\npip install git+\"https://github.com/nliulab/ShapleyVIC#egg=ShapleyVIC&subdirectory=python\"\n\n\nWindows:\n\n\npython.exe -m pip install git+\"https://github.com/nliulab/ShapleyVIC#egg=ShapleyVIC&subdirectory=python\"\n\n\n\n\n\n\n\nNote\n\n\n\n\nShapleyVIC uses a modified version of the SAGE library (version 0.0.4b1), which avoids occasional stack overflow problems on Windows but does not affect variable importance evaluation.\n\n\n\n\n\nR package\n\nRequired: R version 3.5.0 or higher.\n\nRecommended: use latest version of R with RStudio.\n\n\nExecute the following command in R/RStudio to install the R package from GitHub:\n\nif (!require(\"devtools\", quietly = TRUE)) install.packages(\"devtools\")\ndevtools::install_github(\"nliulab/ShapleyVIC/r\")"
  },
  {
    "objectID": "index.html#citation",
    "href": "index.html#citation",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "Citation",
    "text": "Citation\n\nCore paper\n\nNing Y, Ong ME, Chakraborty B, Goldstein BA, Ting DS, Vaughan R, Liu N. Shapley variable importance cloud for interpretable machine learning. Patterns 2022; 3: 100452.\n\n\n\nMethod extension\n\nNing Y, Li S, Ong ME, Xie F, Chakraborty B, Ting DS, Liu N. A novel interpretable machine learning system to generate clinical risk scores: An application for predicting early mortality or unplanned readmission in a retrospective cohort study. PLOS Digit Health 2022; 1(6): e0000062."
  },
  {
    "objectID": "index.html#clinical-applications",
    "href": "index.html#clinical-applications",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "Clinical applications",
    "text": "Clinical applications\n\nDeng X, Ning Y, Saffari SE, Xiao B, Niu C, Ng SYE, Chia N, Choi X, Heng DL, Tan YJ, Ng E, Xu Z, Tay KY, Au WL, Ng A, Tan EK, Liu N, and Tan LCS (2023). Identifying clinical features and blood biomarkers associated with mild cognitive impairment in Parkinson’s Disease using machine learning. European Journal of Neurology, 00:1–9."
  },
  {
    "objectID": "index.html#contact",
    "href": "index.html#contact",
    "title": "ShapleyVIC: Shapley Variable Importance Cloud for Interpretable Machine Learning",
    "section": "Contact",
    "text": "Contact\n\nYilin Ning (Email: yilin.ning@duke-nus.edu.sg)\nNan Liu (Email: liu.nan@duke-nus.edu.sg)"
  },
  {
    "objectID": "ch1_data.html#general-requirements",
    "href": "ch1_data.html#general-requirements",
    "title": "1  Data requirements",
    "section": "1.1 General requirements",
    "text": "1.1 General requirements\n\nCurrently ShapleyVIC applies to binary, ordinal and continuous outcomes.\nCode binary outcomes as 0/1, and ordinal outcomes as integers starting from 0.\nNo space or special characters (e.g., [, ], (, ), ,) in variable names. Replace them using _.\nVariable centering/standardization is not required."
  },
  {
    "objectID": "ch1_data.html#missing-values-and-sparsity",
    "href": "ch1_data.html#missing-values-and-sparsity",
    "title": "1  Data requirements",
    "section": "1.2 Missing values and sparsity",
    "text": "1.2 Missing values and sparsity\n\nHandle missing entries appropriately before applying ShapleyVIC. Missing entry is not supported\nCheck data distribution and handle data sparsity before applying ShapleyVIC. Data sparsity may increase run time and lead to unstable results."
  },
  {
    "objectID": "ch1_data.html#additional-pre-processing-for-high-dimensional-data",
    "href": "ch1_data.html#additional-pre-processing-for-high-dimensional-data",
    "title": "1  Data requirements",
    "section": "1.3 Additional pre-processing for high-dimensional data",
    "text": "1.3 Additional pre-processing for high-dimensional data\n\nAlthough theoretically permissible, it is not advisable to apply ShapleyVIC to data with a large number of variables.\nScreen out variables with low importance (e.g., based on univariable or multivariable analysis p-values) to reduce dimension (e.g., to &lt;50 variables) before applying ShapleyVIC."
  },
  {
    "objectID": "ch1_data.html#general-suggestions-on-the-size-of-explanation-set",
    "href": "ch1_data.html#general-suggestions-on-the-size-of-explanation-set",
    "title": "1  Data requirements",
    "section": "1.4 General suggestions on the size of explanation set",
    "text": "1.4 General suggestions on the size of explanation set\n\nLarger number of variables generally requires larger explanation set for stable results.\nIncrease in the size of explanation set and/or number of variables increases time required to compute ShapleyVIC values.\nUse of &gt;3500 samples in explanation set leads to long run time and is generally not recommended."
  },
  {
    "objectID": "ch2_shapleyvic.html#python-shapleyvic-calculation",
    "href": "ch2_shapleyvic.html#python-shapleyvic-calculation",
    "title": "2  ShapleyVIC for Variable Importance Assessment",
    "section": "2.1 [Python] ShapleyVIC calculation",
    "text": "2.1 [Python] ShapleyVIC calculation\nThis part of the ShapleyVIC workflow is implemented in Python.\nIn this part of the workflow, we load and prepare data, train optimal logistic regression model, generate nearly optimal models, and compute Shapley-based variable importance for each model.\n\n2.1.1 Load data\n\nRead data from CSV or Excel files.\nFor this demo, use the integrated data in the library that contains 7214 samples analyzed in Experiment 1 (i.e., the recidivism prediction study) of the paper.\n\n\nfrom ShapleyVIC import df_compas\n\ncompas = df_compas.load_data()\n# See data description using the following command:\n# help(df_compas.load_data)\ncompas.loc[:5]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ny\nage\nrace\nprior\ngender\njuvenilecrime\ncurrentcharge\ntrain_test\n\n\n\n\n0\n0\n0\n1\n1\n1\n0\ntrain\n\n\n1\n0\n1\n1\n1\n1\n0\ntrain\n\n\n1\n0\n1\n0\n1\n0\n0\ntrain\n\n\n0\n0\n1\n0\n1\n0\n0\ntrain\n\n\n0\n0\n0\n0\n1\n1\n0\ntrain\n\n\n0\n0\n0\n1\n1\n1\n1\ntrain\n\n\n\n\n\n\ny: 2-year recidivism (the binary outcome, 1=event and 0=non-event).\nage, race, prior, gender, juvenilecrime, currentcharge: binary predictors.\ntrain_test: training/explanation set membership indicator (\"train\" for training and \"test\" for explanation). Not to include in models.\n\n\n\n2.1.2 Prepare training and explanation sets\n\nWhen there is sufficient data, users can split the full dataset into a training set to train optimal and nearly optimal models, and an explanation set to compute ShapleyVIC values.\nOtherwise, users may use the full dataset to train models and compute ShapleyVIC values.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAs detailed in Chapter 1, check for and handle data issues before applying ShapleyVIC.\nThis demo will show impact of data sparsity on ShapleyVIC results.\n\n\n\nIn the experiment, we used 10% of the full dataset as explanation set. See Chapter 1 for general suggestions on the size of explanation set.\n\nUse the train_test indicator availableRandom split for general cases\n\n\n\ndat_train = compas.loc[compas['train_test']=='train']\n# Drop the indicator column after using it to split data:\ndat_train = dat_train.drop(columns=['train_test'])\ndat_train.reset_index(drop=True, inplace=True)\n\ndat_expl = compas.loc[compas['train_test']=='test']\ndat_expl = dat_expl.drop(columns=['train_test'])\ndat_expl.reset_index(drop=True, inplace=True)\n\n\n\n\n# Drop the column 'train_test' that indicates set membership in example data:\ncompas = compas.drop(columns=['train_test'])\n# Generate row indices for training and explanation sets:\nfrom sklearn.model_selection import train_test_split\ni_train, i_expl = train_test_split(list(range(compas.shape[0])), \n    test_size=int(0.1 * compas.shape[0]), random_state=0)\n\ndat_train = compas.iloc[i_train, :]\ndat_train.reset_index(drop=True, inplace=True)\n\ndat_expl = compas.iloc[i_expl, :]\ndat_expl.reset_index(drop=True, inplace=True)\n\n\n\n\n\n\n2.1.3 Train optimal model\n\nSpecify training data to initialize the model object and train the optimal model.\nx, y: predictors (as a data frame) and outcome from the training set.\noutcome_type: type of the outcome. Default is “binary” that is most common in clinical applications.\n\nSee Chapter 5 for “ordinal” and Chapter 6 for “continuous”.\n\nx_names_cat: names of categorical predictors. Optional for binary predictors encoded as 0/1.\noutput_dir: the directory to save key outputs to. Will be used as input in the subsequent R workflow.\nsave_data: whether to save x and y to output_dir (default is to save). If not, x and y must be supplied separately in subsequent R analysis.\n\nIn this step, users also need to configure the criterion for defining nearly optimal models (see following sections for detail).\n\nDefault is criterion=\"loss\" that applies to all outcome types, where nearly optimal models exceed minimum loss by no more than epsilon (default is 0.05, i.e., 5%).\ncriterion=\"auc\" or criterion=\"prauc\" is also supported for binary outcomes (but not other outcome types), where nearly optimal models have AUC or PRAUC within the 95% of that for the optimal model.\n\n\nLoss criterionAUC criterionPRAUC criterionLoss criterion, do not save data\n\n\nDefine nearly optimal based on loss, and epsilon = 0.05 (the default) for the range of permissible loss.\nDefault option is to save input data x and y, so that they are not needed as input in the subsequent R workflow.\n\n# Specify the name of outcome, which is 'y' in this example:\ny_name = 'y'\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    outcome_type=\"binary\", \n    x_names_cat=['age','race','prior','gender','juvenilecrime','currentcharge'],\n    output_dir=\"compas_output\"\n)\n# To display the optimal logistic regression trained:\nmodel_object.model_optim.summary().tables[1]\n\n\n\nDefine nearly optimal based on AUC, in this case epsilon is not used. This specification does not affect the optimal model.\nUsers are advised to allocate different output folders when different criterion is selected to avoid confusion. In this example, results are saved to output folder compas_auc_output.\n\n# Specify the name of outcome, which is 'y' in this example:\ny_name = 'y'\nfrom ShapleyVIC import model\nmodel_object_auc = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    outcome_type=\"binary\", criterion=\"auc\",\n    x_names_cat=['age','race','prior','gender','juvenilecrime','currentcharge'],\n    output_dir=\"compas_auc_output\"\n)\n# To display the optimal logistic regression trained:\nmodel_object_auc.model_optim.summary().tables[1]\n\n\n\nDefine nearly optimal based on PRAUC, in this case epsilon is not used. This specification does not affect the optimal model.\nUsers are advised to allocate different output folders when different criterion is selected to avoid confusion. In this example, results are saved to output folder compas_prauc_output.\n\n# Specify the name of outcome, which is 'y' in this example:\ny_name = 'y'\nfrom ShapleyVIC import model\nmodel_object_prauc = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    outcome_type=\"binary\", criterion=\"prauc\",\n    x_names_cat=['age','race','prior','gender','juvenilecrime','currentcharge'],\n    output_dir=\"compas_prauc_output\"\n)\n# To display the optimal logistic regression trained:\nmodel_object_prauc.model_optim.summary().tables[1]\n\n\n\nSpecify save_data=False to avoid saving x and y to output folder. See Chapter 3 for another example.\n\n# Specify the name of outcome, which is 'y' in this example:\ny_name = 'y'\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    outcome_type=\"binary\", \n    x_names_cat=['age','race','prior','gender','juvenilecrime','currentcharge'],\n    output_dir=\"compas_output\", save_data=False\n)\n# To display the optimal logistic regression trained:\nmodel_object.model_optim.summary().tables[1]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ncoef\nstd err\nz\nP\n[0.025\n0.975]\n\n\n\n\nconst\n0.4455\n0.107\n4.160\n0.000\n0.236\n0.655\n\n\nage\n1.5001\n0.187\n8.011\n0.000\n1.133\n1.867\n\n\nrace\n0.4164\n0.053\n7.858\n0.000\n0.313\n0.520\n\n\nprior\n-0.8543\n0.061\n-13.984\n0.000\n-0.974\n-0.735\n\n\ngender\n0.3835\n0.068\n5.651\n0.000\n0.251\n0.517\n\n\njuvenilecrime\n-0.8646\n0.084\n-10.238\n0.000\n-1.030\n-0.699\n\n\ncurrentcharge\n-0.2544\n0.056\n-4.562\n0.000\n-0.364\n-0.145\n\n\n\n\n\n2.1.4 Generate nearly optimal models\nAs mentioned above, by default (i.e., criterion=\"loss\", epsilon = 0.05) nearly optimal logistic regression models are defined as models with logistic loss less than \\((1+\\varepsilon)\\) times the minimum loss (i.e., logistic loss of the optimal model). Default value for \\(\\varepsilon\\) is 5%.\nWhen criterion=\"auc\" or criterion=\"prauc\" is specified, nearly optimal logistic regression models are defined as models with AUC (or PRAUC) within the 95% CI of that of the optimal logistic regression model.\nThe criterion (and epsilon) specified when initializing the model object is used to configure and sample nearly optimal models in the following steps.\n\nu1 and u2 are key hyper-parameters for generating nearly optimal models, which control the sampling range of initial models to fully explore the model space.\nUse the following command to generate a set of reasonable values for u1 and u2 (using m=200 initial models), such that approximately 70%-80% of initial models are eligible.\n\nThe same command applies for all criterion but output varies.\n\n\n\nOutput for loss criterion (default)Output for AUC criterionOutput for PRAUC criterion\n\n\n\nu1, u2 = model_object.init_hyper_params(m=200)\n(u1, u2)\n\nNearly optimal defined based on loss with epsilon=0.05.\n\n\n(0.5, 80.3125)\n\n\n\nu1, u2 = model_object_auc.init_hyper_params(m=200)\n(u1, u2)\n\nNearly optimal defined based on auc.\n\n\n(0.5, 38.125)\n\n\n\nu1, u2 = model_object_prauc.init_hyper_params(m=200)\n(u1, u2)\n\nNearly optimal defined based on prauc.\n\n\n(0.5, 32.5)\n\n\n\n\nUse the following command to generate a final set of nearly optimal models (e.g., n_final=250) from 500 initial samples (m=500).\n\nThe same command applies for all criterion but outputs vary.\n\n\n\nLoss criterion (default)AUC criterionPRAUC criterion\n\n\n\nmodel_object.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object.models_plot\n\n\n\n\n\n\n\n\nmodel_object.models_near_optim.iloc[:5]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst\nage_1\nrace_1\nprior_1\ngender_1\njuvenilecrime_1\ncurrentcharge_1\nperf_metric\n\n\n\n\n-0.2307\n3.1195\n0.5047\n-1.1409\n0.2644\n-0.1170\n0.2664\n1.0280\n\n\n0.5503\n0.7759\n0.8971\n-1.1164\n-0.3083\n-0.6398\n-0.1481\n1.0285\n\n\n0.1068\n0.8697\n-0.0176\n-0.6963\n0.6987\n-0.5041\n-0.1812\n1.0187\n\n\n0.9715\n0.8669\n-0.1101\n-1.0772\n0.6450\n-1.3590\n-0.3310\n1.0212\n\n\n-1.0476\n2.0026\n0.6911\n-0.3203\n1.4661\n-0.6633\n-0.0397\n1.0438\n\n\n0.4006\n1.6629\n0.1719\n-0.5450\n0.3218\n-0.9498\n0.6260\n1.0445\n\n\n\n\n\n\n\n\nmodel_object_auc.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object_auc.models_plot\n\n\n\n\n\n\n\n\nmodel_object_auc.models_near_optim.iloc[:5]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst\nage_1\nrace_1\nprior_1\ngender_1\njuvenilecrime_1\ncurrentcharge_1\nperf_metric\n\n\n\n\n0.1989\n2.5653\n0.5665\n-1.6820\n0.7333\n-0.4778\n-0.5296\n0.6742\n\n\n0.5184\n0.9964\n0.7507\n-1.0366\n-0.0977\n-0.7082\n-0.1805\n0.6671\n\n\n0.8325\n1.7529\n0.5860\n-1.0563\n0.0572\n-0.8658\n-0.2591\n0.6785\n\n\n0.2104\n1.0626\n0.1152\n-0.7446\n0.6022\n-0.6144\n-0.2036\n0.6758\n\n\n0.8113\n1.0597\n0.0502\n-1.0093\n0.5654\n-1.2084\n-0.3077\n0.6751\n\n\n0.4500\n1.7156\n0.4195\n-0.9999\n0.4521\n-0.7532\n-0.5512\n0.6765\n\n\n\n\n\n\n\n\nmodel_object_prauc.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object_prauc.models_plot\n\n\n\n\n\n\n\n\nmodel_object_prauc.models_near_optim.iloc[:5]\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nconst\nage_1\nrace_1\nprior_1\ngender_1\njuvenilecrime_1\ncurrentcharge_1\nperf_metric\n\n\n\n\n0.2178\n2.4837\n0.5550\n-1.6186\n0.7065\n-0.5075\n-0.5085\n0.6557\n\n\n0.5161\n1.4747\n0.5260\n-0.7212\n0.3116\n-0.9734\n-0.3726\n0.6636\n\n\n0.7843\n1.0923\n0.0772\n-0.9979\n0.5519\n-1.1830\n-0.3038\n0.6605\n\n\n0.4497\n1.6994\n0.4193\n-0.9889\n0.4469\n-0.7616\n-0.5288\n0.6631\n\n\n-0.3412\n0.7137\n0.3837\n-0.9295\n1.2320\n-0.6347\n-0.2812\n0.6622\n\n\n-0.5807\n0.5378\n0.9135\n-0.9719\n0.6827\n-0.4119\n-0.4054\n0.6583\n\n\n\n\n\n\n\n\n\n\n2.1.5 Assess variable importance\nThis step assesses variable importance for each nearly optimal model generated in the previous step using the SAGE method, and write the results to the output folder for further processing in the subsequent R workflow. Parallel processing is used to reduce run time.\n\nmodel_object: the model object created above.\nx_expl, y_expl: predictors (as a data frame) and outcome from the explanation set.\nn_cores: number of CPU cores to use in parallel processing.\n\nFor a computer with n cores, do not use more than n-1 cores.\n\nthreshold: threshold parameter used in SAGE algorithm for convergence criterion. A reasonable value is 0.05 (default).\n\nSmaller threshold value may improve accuracy of uncertainty measure but notably increases run time.\n\nThe same command applies for all criterion.\n\n\nLoss criterionAUC criterionPRAUC criterion\n\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=7, # running on a MacBook Air with 8 cores\n    threshold=0.05\n)\n\n\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object_auc, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=7, # running on a MacBook Air with 8 cores\n    threshold=0.05\n)\n\n\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object_prauc, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=7, # running on a MacBook Air with 8 cores\n    threshold=0.05\n)\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nUse built-in software (e.g., Activity Monitor/Task Manager) to monitor CPU and Memory usage. Avoid taking up 100% CPU, which can slow down computation.\nThis step can be time consuming with larger number of variables and/or larger explanation data.\nFor users’ reference, the commands above took approximately 10-20 minutes on a 2022 MacBook Air (Apple M2 chip with 8‑core CPU, 8-core GPU; 16GB unified memory; 256GB SSD storage)."
  },
  {
    "objectID": "ch2_shapleyvic.html#r-shapleyvic-summary-and-visualizations",
    "href": "ch2_shapleyvic.html#r-shapleyvic-summary-and-visualizations",
    "title": "2  ShapleyVIC for Variable Importance Assessment",
    "section": "2.2 [R] ShapleyVIC summary and visualizations",
    "text": "2.2 [R] ShapleyVIC summary and visualizations\nThis part of the ShapleyVIC workflow is implemented in R.\nThis part of the workflow works on output from Python (all saved in output_dir), pooling information across models to compute (and visualize) overall variable importance and derive ensemble variable rankings.\n\n2.2.1 Compute overall importance\nAs detailed in the paper, raw Shapley-based variable importance needs to be adjusted based on variable colinearity to derive final ShapleyVIC values.\n\noutput_dir: output folder generated from the Python workflow.\noutcome_type: type of outcome, as specified in the Python workflow.\ncriterion: criterion to define nearly optimal models, as used in the Python workflow.\n\nLoss criterion is assumed by default.\n\nx and y: training data specified in the Python workflow, required if save_data=False was specified when setting up model.models(...) in Python.\nx_names_cat: names of categorical variables, as specified in the Python workflow. Used when assessing variable colinearity from the training set. Optional for binary variables coded as 0/1.\nx_names_display: variable names to use in summary statistics and visualizations. If not provided, column names in the training set will be used.\n\n\nLoss criterionAUC criterionPRAUC criterionLoss criterion, data not saved in Python workflow\n\n\n\nlibrary(ShapleyVIC)\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = \"compas_output\", outcome_type = \"binary\", \n  x_names_cat = c('age','race','prior','gender','juvenilecrime','currentcharge'),\n  x_names = c(\"Age\", \"Race\", \"Prior criminal history\", \"Gender\", \n              \"Juvenile criminal history\", \"Current charge\")\n)\n\nCompiling results for binary outcome using loss criterion to define neaerly optimal models.\n\n\n\n\n\nlibrary(ShapleyVIC)\nmodel_object_auc &lt;- compile_shapley_vic(\n  output_dir = \"compas_auc_output\", outcome_type = \"binary\", criterion = \"auc\",\n  x_names_cat = c('age','race','prior','gender','juvenilecrime','currentcharge'),\n  x_names = c(\"Age\", \"Race\", \"Prior criminal history\", \"Gender\", \n              \"Juvenile criminal history\", \"Current charge\")\n)\n\nCompiling results for binary outcome using auc criterion to define neaerly optimal models.\n\n\n\n\n\nlibrary(ShapleyVIC)\nmodel_object_prauc &lt;- compile_shapley_vic(\n  output_dir = \"compas_prauc_output\", outcome_type = \"binary\", criterion = \"prauc\",\n  x_names_cat = c('age','race','prior','gender','juvenilecrime','currentcharge'),\n  x_names = c(\"Age\", \"Race\", \"Prior criminal history\", \"Gender\", \n              \"Juvenile criminal history\", \"Current charge\")\n)\n\nCompiling results for binary outcome using prauc criterion to define neaerly optimal models.\n\n\n\n\nWhen training data was not saved in the Python workflow, they must be supplied as input (x and y) in this step. See Chapter 3 for another example.\n\n# Prepare training data the same way as in Python workflow:\nlibrary(ShapleyVIC)\nlibrary(dplyr)\ndata(\"df_compas\")\n# Use the `train_test` indicator to filter out training data used in Python workflow:\ndf_train &lt;- df_compas %&gt;% filter(train_test == \"train\") %&gt;% \n  select(-train_test) %&gt;% as.data.frame()\ny_name &lt;- \"y\"\nx_names &lt;- setdiff(names(df_train), y_name)\n# Supply x and y when compiling results from Python workflow:\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = \"compas_output\", outcome_type = \"binary\", \n  x = df_train[, x_names], y = df_train[, y_name],\n  x_names_cat = c('age','race','prior','gender','juvenilecrime','currentcharge'),\n  x_names = c(\"Age\", \"Race\", \"Prior criminal history\", \"Gender\", \n              \"Juvenile criminal history\", \"Current charge\")\n)\n\n\n\n\n\n\n2.2.2 Visualize overall variable importance\nEach ShapleyVIC value (shapley_vic_val) is reported with a standard deviation (sage_sd). We pool information across models to compute overall variable importance and uncertainty interval, visualized using bar plot. The relationship between variable importance and model performance is visualized using violin plot.\n\nThe same command applies for all criterion and generates similar results.\nFor clarity, in the bar plot variables with significant overall importance are indicated by blue color and “*” next to variable names.\n\n\nResults from loss criterionResults from AUC criterionResults from PRAUC criterion\n\n\n\nmodel_plots &lt;- plot(model_object)\n\n\n\n\n\n\n\n\n\n\nmodel_auc_plots &lt;- plot(model_object_auc)\n\n\n\n\n\n\n\n\n\n\nmodel_prauc_plots &lt;- plot(model_object_prauc)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNote\n\n\n\n\nPlots above reproduce key findings reported in the paper: race had non-significant overall importance, and prior criminal history and juvenile criminal history had higher overall importance than other variables.\nOverall importance of age now becomes non-significant when loss or AUC crterion were used, showing that data sparsity (only 20 [2.8%] of 721 subjects had age=1 in explanation data) leads to less stable results.\n\n\n\nThe bar plot can be further edited using ggplot functions, e.g., edit text font size using theme() or add plot title using labs():\n\nlibrary(ggplot2)\nmodel_plots$bar + theme(text = element_text(size = 14)) + labs(title = \"Bar plot\")\n\nTo apply similar formatting to the violin plot, use the following function:\n\nlibrary(ggplot2)\nplot_violin(x = model_object, title = \"Violin plot\", \n            plot_theme = theme(text = element_text(size = 14)))\n\n\n\n2.2.3 Ensemble variable ranking\nShapleyVIC values can also be used to rank variables by their importance to each model. The bar plot of ranks may help identify models with increased reliance on specific variable of interest for further investigation.\nThe same command applies for all criterion. The example below illustrates for the model object using loss criterion.\n\nval_ranks &lt;- rank_variables(model_object)\nhead(val_ranks, 6)\n\n  model_id                  Variable rank\n1        0                       Age    5\n2        0                      Race    3\n3        0    Prior criminal history    1\n4        0                    Gender    3\n5        0 Juvenile criminal history    2\n6        0            Current charge    5\n\nlibrary(ggplot2)\nggplot(val_ranks, aes(x = rank, group = Variable)) + \n  geom_bar() + \n  facet_wrap(~ Variable, nrow = 2) + \n  theme_bw() + \n  labs(x = \"Ranking\", y = \"\", \n       title = \"ShapleyVIC: Variable ranking among 250 models\")\n\n\n\n\nThe ensemble ranking averages the ranks across models, and can be used to guide downstream model building, e.g., using AutoScore. See the next chapter for detailed demonstration.\n\nrank_variables(model_object, summarise = TRUE)\n\n                   Variable mean_rank\n1 Juvenile criminal history     1.196\n2    Prior criminal history     1.492\n\n# To return variable ranking as named vector for convenient integration with \n# AutoScore:\nrank_variables(model_object, summarise = TRUE, as_vector = TRUE)\n\nJuvenile criminal history    Prior criminal history \n                    1.196                     1.492"
  },
  {
    "objectID": "ch3_autoscore_shapleyvic.html#r-prepare-data",
    "href": "ch3_autoscore_shapleyvic.html#r-prepare-data",
    "title": "3  AutoScore-ShapleyVIC for Interpretable Risk Score Development",
    "section": "3.1 [R] Prepare data",
    "text": "3.1 [R] Prepare data\nThis part of the workflow is implemented in R.\n\n3.1.1 Load R packages and data\n\nif (!require(AutoScore, quietly = TRUE)) install.packages(\"AutoScore\")\nlibrary(AutoScore)\nlibrary(tidyverse) # For convenient data manipulation and visualization\n\n# Read the final clean data with 41 candidate variables and the binary outcome \n# (`label`):\ndat &lt;- readRDS(\"dat_readmit_or_death.RDS\")\n\n\n\n3.1.2 Prepare training, validation and test datasets\n\nUse the split_data() function of the AutoScore package to split data into training (70%), validation (10%) and test (20%) sets for risk score development.\nPerform median imputation for vital signs and lab tests based on training set.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAs detailed in Chapter 1, handle missingness (and any other potential data issue) before applying ShapleyVIC.\n\n\n\n\nset.seed(1234)\nOut_split &lt;- split_data(data = dat, ratio = c(7, 1, 2))\n# Median imputation for vital signs and lab tests based on training set:\ntrain_lab_test &lt;- Out_split$train_set %&gt;% select(Pulse:SODIUM)\ntrain_lab_test_median &lt;- apply(train_lab_test, 2, function(x) median(x, na.rm = TRUE))\nOut_split &lt;- lapply(Out_split, function(dat) {\n  for (nm in names(train_lab_test)) {\n    dat[, nm] &lt;- ifelse(is.na(dat[, nm]), train_lab_test_median[nm], dat[, nm])\n  }\n  dat\n})\n\ntrain_set &lt;- Out_split$train_set\nvalidation_set &lt;- Out_split$validation_set\ntest_set &lt;- Out_split$test_set\n\n\nPrepare output_dir for ShapleyVIC, using train_set as training set and the first 3500 observations in validation_set as the explanation data.\n\n\noutput_dir &lt;- \"score_output\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\nwrite.csv(train_set, file = file.path(output_dir, \"train_set.csv\"), \n          row.names = FALSE)\nwrite.csv(validation_set[1:3500, ], \n          file = file.path(output_dir, \"validation_set.csv\"), \n          row.names = FALSE)"
  },
  {
    "objectID": "ch3_autoscore_shapleyvic.html#python-compute-shapleyvic-values",
    "href": "ch3_autoscore_shapleyvic.html#python-compute-shapleyvic-values",
    "title": "3  AutoScore-ShapleyVIC for Interpretable Risk Score Development",
    "section": "3.2 [Python] Compute ShapleyVIC values",
    "text": "3.2 [Python] Compute ShapleyVIC values\nThis part of the workflow is implemented in Python.\n\nLoad data and set up input information.\nData used in this analysis is sensitive, therefore we do not save training data to the output folder to avoid any potential data security issue.\n\n\nimport os\nimport pandas as pd\noutput_dir = \"score_output\"\ndat_train = pd.read_csv(os.path.join(output_dir, 'train_set.csv'))\ndat_expl = pd.read_csv(os.path.join(output_dir, 'validation_set.csv'))\n\ny_name = 'label'\nx_names_cat = ['Gender','Race','Triage_Class_Code','DayofWeek','MI','CHF','PVD',\n    'Stroke','Dementia','Pulmonary','Rheumatic','PUD','LiverMild','Diabetes',\n    'DMcx','Paralysis','Renal','Cancer','LiverSevere','Mets','admit_cat',\n    'resuscitation','VENTILATION']\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    x_names_cat=x_names_cat, outcome_type=\"binary\", output_dir=output_dir,\n    save_data=False\n)\n\n\nDraw 350 nearly optimal models.\n\n\nmodel_object.draw_models(u1=0.2, u2=300, m=800, n_final=350)\n\n\nCompute ShapleyVIC values.\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=10, # running on a PC with 40 logical processors\n    threshold=0.025\n)"
  },
  {
    "objectID": "ch3_autoscore_shapleyvic.html#r-develop-risk-score",
    "href": "ch3_autoscore_shapleyvic.html#r-develop-risk-score",
    "title": "3  AutoScore-ShapleyVIC for Interpretable Risk Score Development",
    "section": "3.3 [R] Develop risk score",
    "text": "3.3 [R] Develop risk score\nThis part of the workflow is implemented in R.\n\n3.3.1 Rank variables using ShapleyVIC\n\nCompile ShapleyVIC output.\nSince data was not saved in the Python workflow, we explicitly specify it in the R analysis.\nExplicitly specify names of categorical variables, identical to those specified in the Python workflow.\n\n\noutput_dir &lt;- \"score_output\"\nx_names_display &lt;- c(\n  \"Age\", \"Gender\", \"Race\", \"ED LOS\", \"ED triage\", \n  \"ED boarding time\", \"Consultation waiting time\", \"No. ED visit\", \n  \"Day of week\", \"Inpatient LOS\", \"Ventilation\", \"Resuscitation\", \n  \"No. surgery\", \"No. ICU stay\", \n  \"No. HD stay\", \"Pulse\", \"Respiration\", \"SpO2\", \n  \"DBP\", \"SBP\", \"Bicarbonate\", \"Creatinine\", \n  \"Potasium\", \"Sodium\", \"MI\", \"CHF\", \"PVD\", \"Stroke\", \n  \"Dementia\", \"Pulmonary\", \"Rheumatic\", \"PUD\", \"Mild liver disease\", \n  \"Diabetes\", \"Diabetes with complications\", \"Paralysis\", \"Renal\", \"Cancer\", \n  \"Severe liver disease\", \"Metastatic cancer\", \"Admission type\"\n)\ny_name &lt;- \"label\"\nx_names &lt;- setdiff(names(train_set), y_name)\nlibrary(ShapleyVIC)\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = output_dir, outcome_type = \"binary\", \n  x = train_set[, x_names], y = train_set$label,\n  x_names_cat = c(\n    'Gender','Race','Triage_Class_Code','DayofWeek','MI','CHF','PVD',\n    'Stroke','Dementia','Pulmonary','Rheumatic','PUD','LiverMild','Diabetes',\n    'DMcx','Paralysis','Renal','Cancer','LiverSevere','Mets','admit_cat',\n    'resuscitation','VENTILATION'\n  ),\n  x_names = x_names_display\n)\n\n\nVisualize ShapleyVIC values for overall variable importance.\n\n\nmodel_plots &lt;- plot(model_object)\n\nThe following variables are excluded due to zero importance in all models analysed:\n\n\n     Ventilation \n\n\n\n\n\n\n\n\n\nDerive ShapleyVIC-based ensemble variable ranking.\n\n\nranking &lt;- rank_variables(model_object, summarise = TRUE, as_vector = TRUE)\nranking\n\n               No. ED visit           Metastatic cancer \n                   1.000000                    2.182857 \n                        Age                      Sodium \n                   3.057143                    6.931429 \n                      Renal                   ED triage \n                   6.945714                    7.428571 \n       Severe liver disease                         CHF \n                   9.071429                   10.365714 \n                 Creatinine                         PVD \n                  10.642857                   12.074286 \n                        SBP                      Cancer \n                  14.120000                   14.597143 \n              Inpatient LOS                      ED LOS \n                  16.105714                   16.908571 \n         Mild liver disease                   Pulmonary \n                  17.785714                   18.040000 \n                   Dementia Diabetes with complications \n                  19.697143                   20.291429 \n                      Pulse                          MI \n                  20.691429                   21.214286 \n                     Stroke \n                  24.185714 \n\n\n\n\n3.3.2 Develop risk score using AutoScore workflow\n\nModify variable names in training, validation and test sets for publication-ready figures and printed output.\n\n\n# Current raw variable names:\nnames(train_set)\n\n [1] \"label\"                     \"Age\"                      \n [3] \"Gender\"                    \"Race\"                     \n [5] \"ED_LOS\"                    \"Triage_Class_Code\"        \n [7] \"EDBoardingTime\"            \"ConsultationWaitingTime\"  \n [9] \"n_ed_6mth\"                 \"DayofWeek\"                \n[11] \"LOS_inp\"                   \"VENTILATION\"              \n[13] \"resuscitation\"             \"Total_Num_Surgery_last1yr\"\n[15] \"Total_icu_count_last1yr\"   \"Total_hd_count_last1yr\"   \n[17] \"Pulse\"                     \"Respiration\"              \n[19] \"SPO2\"                      \"BP_Diastolic\"             \n[21] \"BP_Systolic\"               \"BICARBONATE\"              \n[23] \"CREATININE\"                \"POTASSIUM\"                \n[25] \"SODIUM\"                    \"MI\"                       \n[27] \"CHF\"                       \"PVD\"                      \n[29] \"Stroke\"                    \"Dementia\"                 \n[31] \"Pulmonary\"                 \"Rheumatic\"                \n[33] \"PUD\"                       \"LiverMild\"                \n[35] \"Diabetes\"                  \"DMcx\"                     \n[37] \"Paralysis\"                 \"Renal\"                    \n[39] \"Cancer\"                    \"LiverSevere\"              \n[41] \"Mets\"                      \"admit_cat\"                \n\n# Modified variable names:\nnames(train_set)[-1] &lt;- x_names_display\nnames(train_set)\n\n [1] \"label\"                       \"Age\"                        \n [3] \"Gender\"                      \"Race\"                       \n [5] \"ED LOS\"                      \"ED triage\"                  \n [7] \"ED boarding time\"            \"Consultation waiting time\"  \n [9] \"No. ED visit\"                \"Day of week\"                \n[11] \"Inpatient LOS\"               \"Ventilation\"                \n[13] \"Resuscitation\"               \"No. surgery\"                \n[15] \"No. ICU stay\"                \"No. HD stay\"                \n[17] \"Pulse\"                       \"Respiration\"                \n[19] \"SpO2\"                        \"DBP\"                        \n[21] \"SBP\"                         \"Bicarbonate\"                \n[23] \"Creatinine\"                  \"Potasium\"                   \n[25] \"Sodium\"                      \"MI\"                         \n[27] \"CHF\"                         \"PVD\"                        \n[29] \"Stroke\"                      \"Dementia\"                   \n[31] \"Pulmonary\"                   \"Rheumatic\"                  \n[33] \"PUD\"                         \"Mild liver disease\"         \n[35] \"Diabetes\"                    \"Diabetes with complications\"\n[37] \"Paralysis\"                   \"Renal\"                      \n[39] \"Cancer\"                      \"Severe liver disease\"       \n[41] \"Metastatic cancer\"           \"Admission type\"             \n\nnames(validation_set)[-1] &lt;- x_names_display\nnames(test_set)[-1] &lt;- x_names_display\n\n\nBased on the ensemble variable ranking, apply AutoScore STEP(ii) to select the best model with parsimony plot.\n\n\nAUC &lt;- AutoScore_parsimony(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = length(ranking)\n)\n\nSelect 1 Variable(s):  Area under the curve: 0.6811\nSelect 2 Variable(s):  Area under the curve: 0.706\nSelect 3 Variable(s):  Area under the curve: 0.7406\nSelect 4 Variable(s):  Area under the curve: 0.7467\nSelect 5 Variable(s):  Area under the curve: 0.7555\nSelect 6 Variable(s):  Area under the curve: 0.7589\nSelect 7 Variable(s):  Area under the curve: 0.7595\nSelect 8 Variable(s):  Area under the curve: 0.7605\nSelect 9 Variable(s):  Area under the curve: 0.7624\nSelect 10 Variable(s):  Area under the curve: 0.7637\nSelect 11 Variable(s):  Area under the curve: 0.765\nSelect 12 Variable(s):  Area under the curve: 0.7674\nSelect 13 Variable(s):  Area under the curve: 0.7696\nSelect 14 Variable(s):  Area under the curve: 0.7708\nSelect 15 Variable(s):  Area under the curve: 0.7708\nSelect 16 Variable(s):  Area under the curve: 0.7713\nSelect 17 Variable(s):  Area under the curve: 0.7713\nSelect 18 Variable(s):  Area under the curve: 0.7712\nSelect 19 Variable(s):  Area under the curve: 0.7713\nSelect 20 Variable(s):  Area under the curve: 0.7715\nSelect 21 Variable(s):  Area under the curve: 0.7718\n\n\n\n\n\n\nThis parsimony is somewhat smoother than that from random forest-based variable ranking used in AutoScore.\nA feasible choice is to select the top 6 variables, as adding additional variables does not substantially improve model performance.\nApply AutoScore STEP(iii) to build initial scores from the top 6 variables.\n\n\ncut_vec &lt;- AutoScore_weighting(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = names(ranking)[1:6], max_score = 100\n)\n\n****Included Variables: \n      variable_name\n1      No. ED visit\n2 Metastatic cancer\n3               Age\n4            Sodium\n5             Renal\n6         ED triage\n****Initial Scores: \n\n\n=================  =========  =====\nvariable           interval   point\n=================  =========  =====\nNo. ED visit       &lt;1           0  \n                   [1,3)       14  \n                   &gt;=3         32  \n                                   \nMetastatic cancer  0            0  \n                   1           22  \n                                   \nAge                &lt;28          0  \n                   [28,46)      5  \n                   [46,78)     11  \n                   [78,87)     14  \n                   &gt;=87        19  \n                                   \nSodium             &lt;126        11  \n                   [126,132)    8  \n                   [132,138)    3  \n                   [138,141)    0  \n                   &gt;=141        3  \n                                   \nRenal              0            0  \n                   1            8  \n                                   \nED triage          P1           8  \n                   P2           5  \n                   P3 and P4    0  \n=================  =========  =====\n\n\n\n\n\n***Performance (based on validation set):\nAUC:  0.7589   95% CI: 0.7525-0.7654 (DeLong)\nBest score threshold: &gt;= 27 \nOther performance indicators based on this score threshold: \nSensitivity: 0.7546\nSpecificity: 0.6338\nPPV:         0.2888\nNPV:         0.9291\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\nUsers can apply additional AutoScore STEPs for subsequent model fine-tuning and evaluation."
  },
  {
    "objectID": "ch4_autoscore_shapleyvic_reprod.html#r-prepare-data",
    "href": "ch4_autoscore_shapleyvic_reprod.html#r-prepare-data",
    "title": "4  AutoScore-ShapleyVIC Reproducible Example",
    "section": "4.1 [R] Prepare data",
    "text": "4.1 [R] Prepare data\nThis part of the workflow is implemented in R.\n\n4.1.1 Load data\n\nLoad sample_data from the AutoScore package.\nAs required by AutoScore, change the name of outcome variable to label.\nRead AutoScore Guidebook for detailed data requirement.\n\n\nlibrary(AutoScore)\ndata(\"sample_data\")\nnames(sample_data)[names(sample_data) == \"Mortality_inpatient\"] &lt;- \"label\"\ncheck_data(sample_data)\n\nData type check passed. \n\n\nNo NA in data. \n\ndim(sample_data)\n\n[1] 20000    22\n\n\n\nAs required by ShapleyVIC, code the binary outcome as 0/1.\nAll variables are continuous.\n\n\nsample_data$label &lt;- as.numeric(sample_data$label == \"TRUE\")\nhead(sample_data)\n\n  Vital_A Vital_B Vital_C Vital_D Vital_E Vital_F Vital_G Lab_A Lab_B Lab_C\n1      87     143      78     101      13    35.7      99   160  13.0    23\n2      43     133      64      83      20    36.1      95   116  15.3    24\n3      80     115      48      72      23    37.4      99   133   8.0    27\n4     106     121      68      84      16    37.6      99   206  12.1    25\n5      86     135      70      83      24    37.2      96   100  18.1    26\n6      69     123      72      88      16    36.5      95   204  19.9    20\n  Lab_D Lab_E Lab_F Lab_G Lab_H Lab_I Lab_J Lab_K Lab_L Lab_M Age label\n1   0.0   105    34    12   0.8    98   4.4     0   136    16  66     0\n2   0.8   108    36    12   0.6   322   4.3    55   141    17  79     0\n3   1.3   111    30    11   2.9     0   4.4    40   142     0  86     0\n4   0.0   102    39    14   3.0   214   4.4     0   134     6  69     0\n5   2.3    96    36    13   2.7   326   3.8    20   134    26  65     0\n6   2.5   101    31    10   0.8   103   4.2    38   138    14  68     0\n\n\n\n\n4.1.2 Prepare training, validation, and test datasets\n\nGiven large sample size (n=20000), split the data into training (70%), validation (10%) and test (20%) sets for risk score development.\n\n\nset.seed(4)\nout_split &lt;- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))\ntrain_set &lt;- out_split$train_set\ndim(train_set)\n\n[1] 14000    22\n\nvalidation_set &lt;- out_split$validation_set\ndim(validation_set)\n\n[1] 2000   22\n\ntest_set &lt;- out_split$test_set\ndim(test_set)\n\n[1] 4000   22\n\n\n\nPrepare output_dir for ShapleyVIC, using train_set as training set and validation_set as the explanation data.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAs detailed in Chapter 1, check for and handle data issues before applying ShapleyVIC.\nThis demo uses data as-is because it is simulated clean data.\n\n\n\n\noutput_dir &lt;- \"mort_output\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\nwrite.csv(train_set, file = file.path(output_dir, \"train_set.csv\"), \n          row.names = FALSE)\nwrite.csv(validation_set, \n          file = file.path(output_dir, \"validation_set.csv\"), \n          row.names = FALSE)"
  },
  {
    "objectID": "ch4_autoscore_shapleyvic_reprod.html#python-compute-shapleyvic-values",
    "href": "ch4_autoscore_shapleyvic_reprod.html#python-compute-shapleyvic-values",
    "title": "4  AutoScore-ShapleyVIC Reproducible Example",
    "section": "4.2 [Python] Compute ShapleyVIC values",
    "text": "4.2 [Python] Compute ShapleyVIC values\nThis part of the workflow is implemented in Python.\n\nLoad data and set up input information.\n\n\nimport os\nimport pandas as pd\noutput_dir = \"mort_output\"\ndat_train = pd.read_csv(os.path.join(output_dir, 'train_set.csv'))\ndat_expl = pd.read_csv(os.path.join(output_dir, 'validation_set.csv'))\n\ny_name = 'label'\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    # No need to specify x_names_cat because all variables are continuous\n    outcome_type=\"binary\", output_dir=output_dir\n)\n\n\nSet values for hyper-parameters u1 and u2.\n\n\nu1, u2 = model_object.init_hyper_params(m=200)\n(u1, u2)\n\n(0.5, 15.625)\n\nDraw 250 nearly optimal models from 500 initial samples.\n\n\nmodel_object.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object.models_plot\n\n\n\n\n\n\n\n\nCompute ShapleyVIC values.\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=25, # running on a PC with 40 logical processors\n    threshold=0.05\n)\n\n\n\n\n\n\n\nNote\n\n\n\n\nFor users’ reference, the command above took approximately 17 hours on a PC (Windows 10 Education; Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz 2.19GHz (2 processors); 128GB RAM)."
  },
  {
    "objectID": "ch4_autoscore_shapleyvic_reprod.html#r-develop-risk-score",
    "href": "ch4_autoscore_shapleyvic_reprod.html#r-develop-risk-score",
    "title": "4  AutoScore-ShapleyVIC Reproducible Example",
    "section": "4.3 [R] Develop risk score",
    "text": "4.3 [R] Develop risk score\nThis part of the workflow is implemented in R.\n\n4.3.1 Rank variables using ShapleyVIC\n\nCompile ShapleyVIC output.\n\n\nlibrary(ShapleyVIC)\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = output_dir, outcome_type = \"binary\"\n)\n\nCompiling results for binary outcome using loss criterion to define neaerly optimal models.\n\n\n\nVisualize ShapleyVIC values for overall variable importance.\n\n\nmodel_plots &lt;- plot(model_object)\n\n\n\n\n\n\n\n\nDerive ShapleyVIC-based ensemble variable ranking.\n\n\nranking &lt;- rank_variables(model_object, summarise = TRUE, as_vector = TRUE)\nranking\n\n    Age   Lab_H Vital_E   Lab_K Vital_A   Lab_B   Lab_M Vital_C   Lab_C   Lab_D \n  1.000   2.116   3.028   4.104   5.588   5.744   8.904   8.940   9.084   9.704 \n  Lab_L   Lab_E Vital_D   Lab_G Vital_B   Lab_J   Lab_F \n 10.120  10.268  11.628  12.952  13.220  13.328  16.052 \n\n\n\n\n4.3.2 Develop risk score using AutoScore workflow\n\nBased on the ensemble variable ranking, apply AutoScore STEP(ii) to select the best model with parsimony plot.\n\n\nAUC &lt;- AutoScore_parsimony(\n  train_set = train_set, validation_set = validation_set, \n  rank = ranking, max_score = 100, n_min = 1, n_max = length(ranking)\n)\n\nSelect 1 Variable(s):  Area under the curve: 0.6649\nSelect 2 Variable(s):  Area under the curve: 0.7466\nSelect 3 Variable(s):  Area under the curve: 0.7881\nSelect 4 Variable(s):  Area under the curve: 0.8009\nSelect 5 Variable(s):  Area under the curve: 0.8137\nSelect 6 Variable(s):  Area under the curve: 0.8268\nSelect 7 Variable(s):  Area under the curve: 0.8232\nSelect 8 Variable(s):  Area under the curve: 0.8234\nSelect 9 Variable(s):  Area under the curve: 0.8215\nSelect 10 Variable(s):  Area under the curve: 0.8286\nSelect 11 Variable(s):  Area under the curve: 0.8267\nSelect 12 Variable(s):  Area under the curve: 0.8294\nSelect 13 Variable(s):  Area under the curve: 0.8281\nSelect 14 Variable(s):  Area under the curve: 0.8246\nSelect 15 Variable(s):  Area under the curve: 0.8293\nSelect 16 Variable(s):  Area under the curve: 0.8275\nSelect 17 Variable(s):  Area under the curve: 0.8278\n\n\n\n\n\n\nThis parsimony is somewhat smoother than that from random forest-based variable ranking used in AutoScore.\nA feasible choice is to select the top 6 variables, as adding additional variables does not substantially improve model performance.\nApply AutoScore STEP(iii) to build initial scores from the top 6 variables.\n\n\ncut_vec &lt;- AutoScore_weighting(\n  train_set = train_set, validation_set = validation_set, \n  final_variables = names(ranking)[1:6], max_score = 100\n)\n\n****Included Variables: \n  variable_name\n1           Age\n2         Lab_H\n3       Vital_E\n4         Lab_K\n5       Vital_A\n6         Lab_B\n****Initial Scores: \n\n\n========  ==========  =====\nvariable  interval    point\n========  ==========  =====\nAge       &lt;35           0  \n          [35,49)       7  \n          [49,76)      17  \n          [76,89)      23  \n          &gt;=89         27  \n                           \nLab_H     &lt;0.2          0  \n          [0.2,1.1)     4  \n          [1.1,3.1)     9  \n          [3.1,4)      15  \n          &gt;=4          18  \n                           \nVital_E   &lt;12           0  \n          [12,15)       2  \n          [15,22)       7  \n          [22,25)      12  \n          &gt;=25         15  \n                           \nLab_K     &lt;8            0  \n          [8,42)        6  \n          [42,58)      11  \n          &gt;=58         14  \n                           \nVital_A   &lt;60           0  \n          [60,73)       1  \n          [73,98)       6  \n          [98,111)     10  \n          &gt;=111        13  \n                           \nLab_B     &lt;8.5          0  \n          [8.5,11.2)    4  \n          [11.2,17)     7  \n          [17,19.8)    10  \n          &gt;=19.8       12  \n========  ==========  =====\n\n\n\n\n\n***Performance (based on validation set):\nAUC:  0.8268   95% CI: 0.7953-0.8583 (DeLong)\nBest score threshold: &gt;= 57 \nOther performance indicators based on this score threshold: \nSensitivity: 0.8065\nSpecificity: 0.6775\nPPV:         0.1736\nNPV:         0.9766\n***The cutoffs of each variable generated by the AutoScore are saved in cut_vec. You can decide whether to revise or fine-tune them \n\n\n\nUsers can apply additional AutoScore STEPs for subsequent model fine-tuning and evaluation."
  },
  {
    "objectID": "ch5_shapleyvic_ord.html#r-prepare-data",
    "href": "ch5_shapleyvic_ord.html#r-prepare-data",
    "title": "5  ShapleyVIC for Ordinal Outcomes",
    "section": "5.1 [R] Prepare data",
    "text": "5.1 [R] Prepare data\nThis part of the workflow is implemented in R.\n\n5.1.1 Load data\n\nLoad sample_data_ordinal from the AutoScore package.\nVariable label is a simulated outcome label with 3 ordered categories.\nAmong the 20 predictor variables, Gender, Util_A and the 5 comorbidity variables (Comorb_A to Comorb_E) are categorical, and the rest are continuous.\n\n\nlibrary(AutoScore)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\ndata(\"sample_data_ordinal\")\nhead(sample_data_ordinal)\n\n  label Age Gender Util_A Util_B Util_C    Util_D Comorb_A Comorb_B Comorb_C\n1     1  63 FEMALE     P2      0   0.00 3.5933333        0        0        0\n2     1  41 FEMALE     P2      0   0.96 3.6288889        0        0        0\n3     1  86   MALE     P1      0   0.00 2.6502778        0        0        0\n4     1  51   MALE     P2      0   0.00 4.9711111        0        0        0\n5     1  23 FEMALE     P1      0   0.00 0.5352778        0        0        0\n6     1  32 FEMALE     P2      0   4.13 4.4008333        0        0        0\n  Comorb_D Comorb_E Lab_A Lab_B Lab_C Vital_A Vital_B Vital_C Vital_D Vital_E\n1        0        0   117   3.9   136      91      19     100      70     152\n2        1        0   500   3.6   114      91      16     100      70     147\n3        0        0    72   4.1   136     100      18      99      65     126\n4        0        0    67   5.0   122      73      17      97      46     100\n5        0        0  1036   4.1   138      74      18      98      89     114\n6        0        0   806   4.1   136      77      18      98      74     157\n  Vital_F\n1    25.7\n2    22.6\n3    25.7\n4    24.9\n5    25.7\n6    25.3\n\ndim(sample_data_ordinal)\n\n[1] 20000    21\n\nsummary(sample_data_ordinal)\n\n label          Age            Gender            Util_A          Util_B       \n 1:16360   Min.   : 18.00   FEMALE:10137   P1       : 3750   Min.   : 0.0000  \n 2: 2449   1st Qu.: 50.00   MALE  : 9863   P2       :11307   1st Qu.: 0.0000  \n 3: 1191   Median : 64.00                  P3 and P4: 4943   Median : 0.0000  \n           Mean   : 61.68                                    Mean   : 0.9267  \n           3rd Qu.: 76.00                                    3rd Qu.: 1.0000  \n           Max.   :109.00                                    Max.   :42.0000  \n     Util_C            Util_D         Comorb_A  Comorb_B  Comorb_C  Comorb_D \n Min.   :  0.000   Min.   : 0.09806   0:18445   0:17401   0:19474   0:18113  \n 1st Qu.:  0.000   1st Qu.: 1.52819   1: 1555   1: 2599   1:  526   1: 1887  \n Median :  0.600   Median : 2.46306                                          \n Mean   :  3.535   Mean   : 2.76030                                          \n 3rd Qu.:  3.970   3rd Qu.: 3.61472                                          \n Max.   :293.680   Max.   :23.39056                                          \n Comorb_E      Lab_A            Lab_B           Lab_C          Vital_A      \n 0:19690   Min.   :  16.0   Min.   :1.500   Min.   :102.0   Min.   :  0.00  \n 1:  310   1st Qu.:  66.0   1st Qu.:3.800   1st Qu.:133.0   1st Qu.: 70.00  \n           Median :  83.0   Median :4.100   Median :136.0   Median : 81.00  \n           Mean   : 146.9   Mean   :4.155   Mean   :135.2   Mean   : 82.67  \n           3rd Qu.: 115.0   3rd Qu.:4.400   3rd Qu.:138.0   3rd Qu.: 93.00  \n           Max.   :3534.0   Max.   :8.800   Max.   :170.0   Max.   :197.00  \n    Vital_B         Vital_C          Vital_D          Vital_E     \n Min.   : 1.00   Min.   :  0.00   Min.   :  5.00   Min.   :  0.0  \n 1st Qu.:17.00   1st Qu.: 97.00   1st Qu.: 62.00   1st Qu.:116.0  \n Median :18.00   Median : 98.00   Median : 70.00   Median :131.0  \n Mean   :17.86   Mean   : 97.96   Mean   : 71.23   Mean   :133.5  \n 3rd Qu.:18.00   3rd Qu.: 99.00   3rd Qu.: 79.00   3rd Qu.:148.0  \n Max.   :48.00   Max.   :100.00   Max.   :180.00   Max.   :262.0  \n    Vital_F     \n Min.   : 2.30  \n 1st Qu.:21.10  \n Median :23.00  \n Mean   :22.82  \n 3rd Qu.:24.80  \n Max.   :44.30  \n\n\n\nRecode the outcome labels to start from 0, which is required by ShapleyVIC.\n\n\nsample_data_ordinal$label &lt;- as.ordered(as.numeric(sample_data_ordinal$label) - 1)\ntable(sample_data_ordinal$label)\n\n\n    0     1     2 \n16360  2449  1191 \n\n\n\n\n5.1.2 Prepare training, validation, and test datasets\n\nGiven large sample size (n=20000), split the data into training (70%), validation (10%) and test (20%) sets for regression model development.\nStratify by the outcome variable (label) when splitting data.\n\n\nset.seed(4)\nout_split &lt;- split_data(data = sample_data_ordinal, ratio = c(0.7, 0.1, 0.2), \n                        strat_by_label = TRUE)\ntrain_set &lt;- out_split$train_set\ndim(train_set)\n\n[1] 14000    21\n\nvalidation_set &lt;- out_split$validation_set\ndim(validation_set)\n\n[1] 2000   21\n\ntest_set &lt;- out_split$test_set\ndim(test_set)\n\n[1] 4000   21\n\n\n\nPrepare ord_output for ShapleyVIC, using train_set as training set and validation_set as the explanation data.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAs detailed in Chapter 1, check for and handle data issues before applying ShapleyVIC. This demo uses data as-is because it is simulated clean data.\nIn this example the validation_set has 2000 samples, which is a reasonable sample size to be used as the explanation data. In cases with larger sample sizes, users should use a smaller subset as the explanation data (see Chapter 1 for detail).\n\n\n\n\noutput_dir &lt;- \"ord_output\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\nwrite.csv(train_set, file = file.path(output_dir, \"train_set.csv\"), \n          row.names = FALSE)\nwrite.csv(validation_set, \n          file = file.path(output_dir, \"validation_set.csv\"), \n          row.names = FALSE)"
  },
  {
    "objectID": "ch5_shapleyvic_ord.html#python-compute-shapleyvic-values",
    "href": "ch5_shapleyvic_ord.html#python-compute-shapleyvic-values",
    "title": "5  ShapleyVIC for Ordinal Outcomes",
    "section": "5.2 [Python] Compute ShapleyVIC values",
    "text": "5.2 [Python] Compute ShapleyVIC values\nThis part of the workflow is implemented in Python.\n\nLoad data and set up input information.\nFor ordinal outcome, specify outcome_type='ordinal'.\n\n\nimport os\nimport pandas as pd\noutput_dir = \"ord_output\"\ndat_train = pd.read_csv(os.path.join(output_dir, 'train_set.csv'))\ndat_expl = pd.read_csv(os.path.join(output_dir, 'validation_set.csv'))\n\ny_name = 'label'\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    x_names_cat=['Gender', 'Util_A', 'Comorb_A', 'Comorb_B', 'Comorb_C', 'Comorb_D', 'Comorb_E'],\n    outcome_type='ordinal', output_dir=output_dir\n)\n\n\nSet values for hyper-parameters u1 and u2.\n\n\nu1, u2 = model_object.init_hyper_params()\n(u1, u2)\n\n(0.5, 43.75)\n\nDraw 250 nearly optimal models from 500 initial samples.\n\n\nmodel_object.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object.models_plot\n\n\n\n\n\n\n\n\nCompute ShapleyVIC values.\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=20, # running on a PC with 40 logical processors\n    threshold=0.05\n)\n\n\n\n\n\n\n\nNote\n\n\n\n\nFor users’ reference, the command above took approximately 18 hours on a PC (Windows 10 Education; Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz 2.19GHz (2 processors); 128GB RAM)."
  },
  {
    "objectID": "ch5_shapleyvic_ord.html#r-develop-prediction-model",
    "href": "ch5_shapleyvic_ord.html#r-develop-prediction-model",
    "title": "5  ShapleyVIC for Ordinal Outcomes",
    "section": "5.3 [R] Develop prediction model",
    "text": "5.3 [R] Develop prediction model\nThis part of the workflow is implemented in R.\n\n5.3.1 Overall variable importance from ShapleyVIC\n\nCompile ShapleyVIC output.\n\n\noutput_dir &lt;- \"ord_output\"\nlibrary(ShapleyVIC)\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = output_dir, outcome_type = \"ordinal\", \n  x_names_cat = c('Gender', 'Util_A', 'Comorb_A', 'Comorb_B', 'Comorb_C', \n                  'Comorb_D', 'Comorb_E')\n)\n\nCompiling results for ordinal outcome using loss criterion to define neaerly optimal models.\n\n\n\nVisualize ShapleyVIC values for overall variable importance.\n\n\nmodel_plots &lt;- plot(model_object)\n\n\n\n\n\n\n\n\n\n5.3.2 ShapleyVIC-assisted backward selection\n\nIdentify variables with significant overall importance.\n\n\nvars_svic &lt;- rank_variables(model_object, summarise = TRUE, as_vector = TRUE) %&gt;%\n  names()\nvars_svic\n\n[1] \"Comorb_A\" \"Age\"      \"Vital_A\"  \"Util_D\"   \"Util_B\"   \"Vital_E\"  \"Vital_B\" \n\n\n\nStarting with a model that include all variables above, develop a sparse regression model using AIC-based stepwise selection (implemented by the MASS package).\nUsing the ordinal package to develop ordinal regression models, more specifically cumulative link model (CLM) with the logit link. See the ordinal package for detailed usage.\n\n\n# Model with all ShapleyVIC-selected variables:\nlibrary(ordinal)\n\n\nAttaching package: 'ordinal'\n\n\nThe following object is masked from 'package:dplyr':\n\n    slice\n\nm_svic_all &lt;- clm(label ~ ., data = train_set[, c(\"label\", vars_svic)])\nsummary(m_svic_all)\n\nformula: label ~ Comorb_A + Age + Vital_A + Util_D + Util_B + Vital_E + Vital_B\ndata:    train_set[, c(\"label\", vars_svic)]\n\n link  threshold nobs  logLik   AIC      niter max.grad cond.H \n logit flexible  14000 -7726.66 15471.32 5(0)  7.24e-07 1.0e+07\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \nComorb_A1  1.5184021  0.0659862  23.011  &lt; 2e-16 ***\nAge        0.0195374  0.0013333  14.654  &lt; 2e-16 ***\nVital_A    0.0105223  0.0012776   8.236  &lt; 2e-16 ***\nUtil_D    -0.0768266  0.0140619  -5.463 4.67e-08 ***\nUtil_B     0.1349605  0.0087143  15.487  &lt; 2e-16 ***\nVital_E   -0.0062609  0.0009181  -6.819 9.14e-12 ***\nVital_B   -0.0039738  0.0127336  -0.312    0.755    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n0|1   2.8254     0.2961   9.543\n1|2   4.1694     0.2980  13.993\n\n# Backward selection:\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nm_svic &lt;- stepAIC(object = m_svic_all, scope = list(upper = ~ ., lower = ~ 1), \n                  trace = FALSE)\nsummary(m_svic)\n\nformula: label ~ Comorb_A + Age + Vital_A + Util_D + Util_B + Vital_E\ndata:    train_set[, c(\"label\", vars_svic)]\n\n link  threshold nobs  logLik   AIC      niter max.grad cond.H \n logit flexible  14000 -7726.71 15469.42 5(0)  7.24e-07 4.1e+06\n\nCoefficients:\n            Estimate Std. Error z value Pr(&gt;|z|)    \nComorb_A1  1.5186641  0.0659814  23.017  &lt; 2e-16 ***\nAge        0.0195405  0.0013332  14.657  &lt; 2e-16 ***\nVital_A    0.0105274  0.0012775   8.240  &lt; 2e-16 ***\nUtil_D    -0.0768318  0.0140616  -5.464 4.66e-08 ***\nUtil_B     0.1349614  0.0087136  15.489  &lt; 2e-16 ***\nVital_E   -0.0062629  0.0009181  -6.822 8.99e-12 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n0|1   2.8967     0.1885   15.37\n1|2   4.2407     0.1914   22.15\n\n# Variables selected:\n(x_svic &lt;- setdiff(names(m_svic$model), \"label\"))\n\n[1] \"Comorb_A\" \"Age\"      \"Vital_A\"  \"Util_D\"   \"Util_B\"   \"Vital_E\" \n\n\n\n\n5.3.3 Compare with conventional backward selection\n\nBackward selection from all candidate variables.\n\n\n# Model with all variables:\nm_all &lt;- clm(formula = label ~ ., data = train_set)\nsummary(m_all)\n\nformula: \nlabel ~ Age + Gender + Util_A + Util_B + Util_C + Util_D + Comorb_A + Comorb_B + Comorb_C + Comorb_D + Comorb_E + Lab_A + Lab_B + Lab_C + Vital_A + Vital_B + Vital_C + Vital_D + Vital_E + Vital_F\ndata:    train_set\n\n link  threshold nobs  logLik   AIC      niter max.grad cond.H \n logit flexible  14000 -7706.19 15458.38 5(0)  8.70e-07 4.2e+08\n\nCoefficients:\n                  Estimate Std. Error z value Pr(&gt;|z|)    \nAge              0.0196646  0.0013361  14.718  &lt; 2e-16 ***\nGenderMALE      -0.0890106  0.0452970  -1.965 0.049409 *  \nUtil_AP2         0.0036111  0.0601693   0.060 0.952144    \nUtil_AP3 and P4 -0.0231994  0.0696219  -0.333 0.738969    \nUtil_B           0.1360881  0.0087351  15.579  &lt; 2e-16 ***\nUtil_C          -0.0003512  0.0024950  -0.141 0.888066    \nUtil_D          -0.0769431  0.0140759  -5.466 4.60e-08 ***\nComorb_A1        1.5267179  0.0661465  23.081  &lt; 2e-16 ***\nComorb_B1        0.0322990  0.0664355   0.486 0.626846    \nComorb_C1        0.2021264  0.1351520   1.496 0.134771    \nComorb_D1        0.0261648  0.0771122   0.339 0.734377    \nComorb_E1       -0.1684798  0.1917073  -0.879 0.379489    \nLab_A            0.0004328  0.0001057   4.092 4.27e-05 ***\nLab_B           -0.0069865  0.0332327  -0.210 0.833489    \nLab_C           -0.0067104  0.0046660  -1.438 0.150389    \nVital_A          0.0106528  0.0012804   8.320  &lt; 2e-16 ***\nVital_B         -0.0040444  0.0127466  -0.317 0.751019    \nVital_C         -0.0013990  0.0069806  -0.200 0.841155    \nVital_D          0.0006639  0.0016693   0.398 0.690843    \nVital_E         -0.0062020  0.0009198  -6.743 1.55e-11 ***\nVital_F         -0.0243927  0.0063573  -3.837 0.000125 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n0|1    1.299      1.010   1.287\n1|2    2.647      1.010   2.620\n\n# Backward selection:\nm_back &lt;- stepAIC(object = m_all, scope = list(upper = ~ ., lower = ~ 1), \n                  trace = FALSE)\nsummary(m_back)\n\nformula: \nlabel ~ Age + Gender + Util_B + Util_D + Comorb_A + Comorb_C + Lab_A + Vital_A + Vital_E + Vital_F\ndata:    train_set\n\n link  threshold nobs  logLik   AIC      niter max.grad cond.H \n logit flexible  14000 -7708.06 15440.13 5(0)  8.70e-07 1.8e+07\n\nCoefficients:\n             Estimate Std. Error z value Pr(&gt;|z|)    \nAge         0.0196518  0.0013353  14.717  &lt; 2e-16 ***\nGenderMALE -0.0906919  0.0452646  -2.004  0.04511 *  \nUtil_B      0.1358021  0.0087232  15.568  &lt; 2e-16 ***\nUtil_D     -0.0771132  0.0140754  -5.479 4.29e-08 ***\nComorb_A1   1.5262185  0.0660905  23.093  &lt; 2e-16 ***\nComorb_C1   0.2026533  0.1350978   1.500  0.13360    \nLab_A       0.0004345  0.0001057   4.111 3.94e-05 ***\nVital_A     0.0106409  0.0012794   8.317  &lt; 2e-16 ***\nVital_E    -0.0062111  0.0009193  -6.756 1.42e-11 ***\nVital_F    -0.0243158  0.0063537  -3.827  0.00013 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nThreshold coefficients:\n    Estimate Std. Error z value\n0|1   2.3946     0.2376   10.08\n1|2   3.7417     0.2397   15.61\n\n# Variables selected:\n(x_back &lt;- setdiff(names(m_back$model), \"label\"))\n\n [1] \"Age\"      \"Gender\"   \"Util_B\"   \"Util_D\"   \"Comorb_A\" \"Comorb_C\"\n [7] \"Lab_A\"    \"Vital_A\"  \"Vital_E\"  \"Vital_F\" \n\n\n\nShapleyVIC-assisted backward selection developed a more parsimonious model (with 6 variables) than conventional backward selection (with 10 variables) without significantly impairing performance.\n\n\n# Performance of model from ShapleyVIC-assisted backward selection on test set:\nfx_svic &lt;- model.matrix(~ ., data = test_set[, x_svic])[, -1] %*% m_svic$beta\nprint_performance_ordinal(label = test_set$label, score = as.numeric(fx_svic), \n                          n_boot = 100, report_cindex = TRUE)\n\nmAUC: 0.7291     95% CI: 0.7062-0.7471 (from 100 bootstrap samples)\nGeneralised c-index: 0.6990      95% CI: 0.6803-0.7146 (from 100 bootstrap samples)\n\n# Performance of model from conventional backward selection on test set:\nfx_back &lt;- model.matrix(~ ., data = test_set[, x_back])[, -1] %*% m_back$beta\nprint_performance_ordinal(label = test_set$label, score = as.numeric(fx_back), \n                          n_boot = 100, report_cindex = TRUE)\n\nmAUC: 0.7351     95% CI: 0.7165-0.7559 (from 100 bootstrap samples)\nGeneralised c-index: 0.7033      95% CI: 0.6881-0.7197 (from 100 bootstrap samples)"
  },
  {
    "objectID": "ch6_shapleyvic_cont.html#r-prepare-data",
    "href": "ch6_shapleyvic_cont.html#r-prepare-data",
    "title": "6  ShapleyVIC for Continuous Outcomes",
    "section": "6.1 [R] Prepare data",
    "text": "6.1 [R] Prepare data\nThis part of the workflow is implemented in R.\n\n6.1.1 Load data\n\nLoad sample_data_ordinal from the AutoScore package.\nVariable label is a simulated outcome label with 3 ordered categories.\nAmong the 20 predictor variables, Gender, Util_A and the 5 comorbidity variables (Comorb_A to Comorb_E) are categorical, and the rest are continuous.\n\n\nlibrary(AutoScore)\nlibrary(dplyr)\n\n\nAttaching package: 'dplyr'\n\n\nThe following objects are masked from 'package:stats':\n\n    filter, lag\n\n\nThe following objects are masked from 'package:base':\n\n    intersect, setdiff, setequal, union\n\nlibrary(purrr)\ndata(\"sample_data_ordinal\")\n\nhead(sample_data_ordinal)\n\n  label Age Gender Util_A Util_B Util_C    Util_D Comorb_A Comorb_B Comorb_C\n1     1  63 FEMALE     P2      0   0.00 3.5933333        0        0        0\n2     1  41 FEMALE     P2      0   0.96 3.6288889        0        0        0\n3     1  86   MALE     P1      0   0.00 2.6502778        0        0        0\n4     1  51   MALE     P2      0   0.00 4.9711111        0        0        0\n5     1  23 FEMALE     P1      0   0.00 0.5352778        0        0        0\n6     1  32 FEMALE     P2      0   4.13 4.4008333        0        0        0\n  Comorb_D Comorb_E Lab_A Lab_B Lab_C Vital_A Vital_B Vital_C Vital_D Vital_E\n1        0        0   117   3.9   136      91      19     100      70     152\n2        1        0   500   3.6   114      91      16     100      70     147\n3        0        0    72   4.1   136     100      18      99      65     126\n4        0        0    67   5.0   122      73      17      97      46     100\n5        0        0  1036   4.1   138      74      18      98      89     114\n6        0        0   806   4.1   136      77      18      98      74     157\n  Vital_F\n1    25.7\n2    22.6\n3    25.7\n4    24.9\n5    25.7\n6    25.3\n\ndim(sample_data_ordinal)\n\n[1] 20000    21\n\nsummary(sample_data_ordinal)\n\n label          Age            Gender            Util_A          Util_B       \n 1:16360   Min.   : 18.00   FEMALE:10137   P1       : 3750   Min.   : 0.0000  \n 2: 2449   1st Qu.: 50.00   MALE  : 9863   P2       :11307   1st Qu.: 0.0000  \n 3: 1191   Median : 64.00                  P3 and P4: 4943   Median : 0.0000  \n           Mean   : 61.68                                    Mean   : 0.9267  \n           3rd Qu.: 76.00                                    3rd Qu.: 1.0000  \n           Max.   :109.00                                    Max.   :42.0000  \n     Util_C            Util_D         Comorb_A  Comorb_B  Comorb_C  Comorb_D \n Min.   :  0.000   Min.   : 0.09806   0:18445   0:17401   0:19474   0:18113  \n 1st Qu.:  0.000   1st Qu.: 1.52819   1: 1555   1: 2599   1:  526   1: 1887  \n Median :  0.600   Median : 2.46306                                          \n Mean   :  3.535   Mean   : 2.76030                                          \n 3rd Qu.:  3.970   3rd Qu.: 3.61472                                          \n Max.   :293.680   Max.   :23.39056                                          \n Comorb_E      Lab_A            Lab_B           Lab_C          Vital_A      \n 0:19690   Min.   :  16.0   Min.   :1.500   Min.   :102.0   Min.   :  0.00  \n 1:  310   1st Qu.:  66.0   1st Qu.:3.800   1st Qu.:133.0   1st Qu.: 70.00  \n           Median :  83.0   Median :4.100   Median :136.0   Median : 81.00  \n           Mean   : 146.9   Mean   :4.155   Mean   :135.2   Mean   : 82.67  \n           3rd Qu.: 115.0   3rd Qu.:4.400   3rd Qu.:138.0   3rd Qu.: 93.00  \n           Max.   :3534.0   Max.   :8.800   Max.   :170.0   Max.   :197.00  \n    Vital_B         Vital_C          Vital_D          Vital_E     \n Min.   : 1.00   Min.   :  0.00   Min.   :  5.00   Min.   :  0.0  \n 1st Qu.:17.00   1st Qu.: 97.00   1st Qu.: 62.00   1st Qu.:116.0  \n Median :18.00   Median : 98.00   Median : 70.00   Median :131.0  \n Mean   :17.86   Mean   : 97.96   Mean   : 71.23   Mean   :133.5  \n 3rd Qu.:18.00   3rd Qu.: 99.00   3rd Qu.: 79.00   3rd Qu.:148.0  \n Max.   :48.00   Max.   :100.00   Max.   :180.00   Max.   :262.0  \n    Vital_F     \n Min.   : 2.30  \n 1st Qu.:21.10  \n Median :23.00  \n Mean   :22.82  \n 3rd Qu.:24.80  \n Max.   :44.30  \n\n\n\n\n6.1.2 Prepare training, validation, and test datasets\n\nGiven large sample size (n=20000), split the data into training (70%), validation (10%) and test (20%) sets for regression model development.\nFor convenience, we reuse the stratified data split step from the previous chapter, but convert the outcome (“label”) to continuous.\n\n\nset.seed(4)\nout_split &lt;- split_data(data = sample_data_ordinal, ratio = c(0.7, 0.1, 0.2), \n                        strat_by_label = TRUE)\ntrain_set &lt;- out_split$train_set\n# For this demo, convert the outcome (\"label\") to continuous\ntrain_set$label &lt;- as.numeric(train_set$label)\ndim(train_set)\n\n[1] 14000    21\n\nvalidation_set &lt;- out_split$validation_set\n# For this demo, convert the outcome (\"label\") to continuous\nvalidation_set$label &lt;- as.numeric(validation_set$label)\ndim(validation_set)\n\n[1] 2000   21\n\ntest_set &lt;- out_split$test_set\n# For this demo, convert the outcome (\"label\") to continuous\ntest_set$label &lt;- as.numeric(test_set$label)\ndim(test_set)\n\n[1] 4000   21\n\n\n\nPrepare cont_output for ShapleyVIC, using train_set as training set and validation_set as the explanation data.\n\n\n\n\n\n\n\nImportant\n\n\n\n\nAs detailed in Chapter 1, check for and handle data issues before applying ShapleyVIC. This demo uses data as-is because it is simulated clean data.\nIn this example the validation_set has 2000 samples, which is a reasonable sample size to be used as the explanation data. In cases with larger sample sizes, users should use a smaller subset as the explanation data (see Chapter 1 for detail).\n\n\n\n\noutput_dir &lt;- \"cont_output\"\nif (!dir.exists(output_dir)) dir.create(output_dir)\nwrite.csv(train_set, file = file.path(output_dir, \"train_set.csv\"), \n          row.names = FALSE)\nwrite.csv(validation_set, \n          file = file.path(output_dir, \"validation_set.csv\"), \n          row.names = FALSE)"
  },
  {
    "objectID": "ch6_shapleyvic_cont.html#python-compute-shapleyvic-values",
    "href": "ch6_shapleyvic_cont.html#python-compute-shapleyvic-values",
    "title": "6  ShapleyVIC for Continuous Outcomes",
    "section": "6.2 [Python] Compute ShapleyVIC values",
    "text": "6.2 [Python] Compute ShapleyVIC values\nThis part of the workflow is implemented in Python.\n\nLoad data and set up input information.\nFor continuous outcome, specify outcome_type='continuous'.\n\n\nimport os\nimport pandas as pd\noutput_dir = \"cont_output\"\ndat_train = pd.read_csv(os.path.join(output_dir, 'train_set.csv'))\ndat_expl = pd.read_csv(os.path.join(output_dir, 'validation_set.csv'))\n\ny_name = 'label'\nfrom ShapleyVIC import model\nmodel_object = model.models(\n    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], \n    x_names_cat=['Gender', 'Util_A', 'Comorb_A', 'Comorb_B', 'Comorb_C', 'Comorb_D', 'Comorb_E'],\n    outcome_type='continuous', output_dir=output_dir\n)\n\n\nSet values for hyper-parameters u1 and u2.\n\n\nu1, u2 = model_object.init_hyper_params()\n(u1, u2)\n\n(0.5, 77.5)\n\nDraw 250 nearly optimal models from 500 initial samples.\n\n\nmodel_object.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)\nmodel_object.models_plot\n\n\n\n\n\n\n\n\nCompute ShapleyVIC values.\n\n\nfrom ShapleyVIC import compute\nm_svic = compute.compute_shapley_vic(\n    model_obj=model_object, \n    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], \n    n_cores=20, # running on a PC with 40 logical processors\n    threshold=0.05\n)\n\n\n\n\n\n\n\nNote\n\n\n\n\nFor users’ reference, the command above took approximately 24 hours on a PC (Windows 10 Education; Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz 2.19GHz (2 processors); 128GB RAM)."
  },
  {
    "objectID": "ch6_shapleyvic_cont.html#r-develop-prediction-model",
    "href": "ch6_shapleyvic_cont.html#r-develop-prediction-model",
    "title": "6  ShapleyVIC for Continuous Outcomes",
    "section": "6.3 [R] Develop prediction model",
    "text": "6.3 [R] Develop prediction model\nThis part of the workflow is implemented in R.\n\n6.3.1 Overall variable importance from ShapleyVIC\n\nCompile ShapleyVIC output.\n\n\noutput_dir &lt;- \"cont_output\"\nlibrary(ShapleyVIC)\nmodel_object &lt;- compile_shapley_vic(\n  output_dir = output_dir, outcome_type = \"continuous\", \n  x_names_cat = c('Gender', 'Util_A', 'Comorb_A', 'Comorb_B', 'Comorb_C', \n                  'Comorb_D', 'Comorb_E')\n)\n\nCompiling results for continuous outcome using loss criterion to define neaerly optimal models.\n\n\n\nVisualize ShapleyVIC values for overall variable importance.\n\n\nmodel_plots &lt;- plot(model_object)\n\n\n\n\n\n\n\n\n\n6.3.2 ShapleyVIC-assisted backward selection\n\nIdentify variables with significant overall importance.\n\n\nvars_svic &lt;- rank_variables(model_object, summarise = TRUE, as_vector = TRUE) %&gt;%\n  names()\nvars_svic\n\n[1] \"Comorb_A\" \"Age\"      \"Vital_A\"  \"Util_B\"   \"Lab_A\"   \n\n\n\nStarting with a model that include all variables above, develop a sparse regression model using AIC-based stepwise selection (implemented by the MASS package).\n\n\n# Model with all ShapleyVIC-selected variables:\nm_svic_all &lt;- lm(label ~ ., data = train_set[, c(\"label\", vars_svic)])\nsummary(m_svic_all)\n\n\nCall:\nlm(formula = label ~ ., data = train_set[, c(\"label\", vars_svic)])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.59070 -0.24560 -0.17416 -0.06995  1.98002 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.7564288  0.0268424  28.180  &lt; 2e-16 ***\nComorb_A1   0.4327596  0.0165608  26.131  &lt; 2e-16 ***\nAge         0.0036084  0.0002453  14.707  &lt; 2e-16 ***\nVital_A     0.0021720  0.0002606   8.335  &lt; 2e-16 ***\nUtil_B      0.0370323  0.0020596  17.980  &lt; 2e-16 ***\nLab_A       0.0001014  0.0000225   4.507 6.63e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5258 on 13994 degrees of freedom\nMultiple R-squared:  0.0861,    Adjusted R-squared:  0.08577 \nF-statistic: 263.7 on 5 and 13994 DF,  p-value: &lt; 2.2e-16\n\n# Backward selection:\nlibrary(MASS)\n\n\nAttaching package: 'MASS'\n\n\nThe following object is masked from 'package:dplyr':\n\n    select\n\nm_svic &lt;- stepAIC(object = m_svic_all, scope = list(upper = ~ ., lower = ~ 1), \n                  trace = FALSE)\nsummary(m_svic)\n\n\nCall:\nlm(formula = label ~ Comorb_A + Age + Vital_A + Util_B + Lab_A, \n    data = train_set[, c(\"label\", vars_svic)])\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.59070 -0.24560 -0.17416 -0.06995  1.98002 \n\nCoefficients:\n             Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept) 0.7564288  0.0268424  28.180  &lt; 2e-16 ***\nComorb_A1   0.4327596  0.0165608  26.131  &lt; 2e-16 ***\nAge         0.0036084  0.0002453  14.707  &lt; 2e-16 ***\nVital_A     0.0021720  0.0002606   8.335  &lt; 2e-16 ***\nUtil_B      0.0370323  0.0020596  17.980  &lt; 2e-16 ***\nLab_A       0.0001014  0.0000225   4.507 6.63e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5258 on 13994 degrees of freedom\nMultiple R-squared:  0.0861,    Adjusted R-squared:  0.08577 \nF-statistic: 263.7 on 5 and 13994 DF,  p-value: &lt; 2.2e-16\n\n# Variables selected:\n(x_svic &lt;- setdiff(names(m_svic$model), \"label\"))\n\n[1] \"Comorb_A\" \"Age\"      \"Vital_A\"  \"Util_B\"   \"Lab_A\"   \n\n\n\n\n6.3.3 Compare with conventional backward selection\n\nBackward selection from all candidate variables.\n\n\n# Model with all variables:\nm_all &lt;- lm(label ~ ., data = train_set)\nsummary(m_all)\n\n\nCall:\nlm(formula = label ~ ., data = train_set)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.55915 -0.25176 -0.17028 -0.05685  2.12399 \n\nCoefficients:\n                  Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)      1.287e+00  1.977e-01   6.511 7.75e-11 ***\nAge              3.596e-03  2.447e-04  14.695  &lt; 2e-16 ***\nGenderMALE      -1.563e-02  8.864e-03  -1.763   0.0779 .  \nUtil_AP2        -1.577e-05  1.178e-02  -0.001   0.9989    \nUtil_AP3 and P4 -6.534e-04  1.360e-02  -0.048   0.9617    \nUtil_B           3.718e-02  2.055e-03  18.094  &lt; 2e-16 ***\nUtil_C           5.271e-05  5.093e-04   0.104   0.9176    \nUtil_D          -1.450e-02  2.579e-03  -5.623 1.91e-08 ***\nComorb_A1        4.301e-01  1.652e-02  26.037  &lt; 2e-16 ***\nComorb_B1        8.332e-03  1.323e-02   0.630   0.5288    \nComorb_C1        3.536e-02  2.820e-02   1.254   0.2098    \nComorb_D1        3.266e-03  1.521e-02   0.215   0.8300    \nComorb_E1       -3.646e-02  3.598e-02  -1.013   0.3110    \nLab_A            9.818e-05  2.245e-05   4.374 1.23e-05 ***\nLab_B           -3.988e-03  6.498e-03  -0.614   0.5394    \nLab_C           -1.216e-03  9.222e-04  -1.318   0.1874    \nVital_A          2.174e-03  2.599e-04   8.362  &lt; 2e-16 ***\nVital_B          1.323e-04  2.445e-03   0.054   0.9568    \nVital_C         -3.688e-04  1.364e-03  -0.270   0.7868    \nVital_D          7.918e-05  3.276e-04   0.242   0.8090    \nVital_E         -1.130e-03  1.747e-04  -6.467 1.04e-10 ***\nVital_F         -5.429e-03  1.255e-03  -4.327 1.52e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.5242 on 13978 degrees of freedom\nMultiple R-squared:  0.0927,    Adjusted R-squared:  0.09134 \nF-statistic: 68.01 on 21 and 13978 DF,  p-value: &lt; 2.2e-16\n\n# Backward selection:\nm_back &lt;- stepAIC(object = m_all, scope = list(upper = ~ ., lower = ~ 1), \n                  trace = FALSE)\nsummary(m_back)\n\n\nCall:\nlm(formula = label ~ Age + Gender + Util_B + Util_D + Comorb_A + \n    Lab_A + Vital_A + Vital_E + Vital_F, data = train_set)\n\nResiduals:\n     Min       1Q   Median       3Q      Max \n-1.55557 -0.25120 -0.17067 -0.05771  2.13009 \n\nCoefficients:\n              Estimate Std. Error t value Pr(&gt;|t|)    \n(Intercept)  1.080e+00  4.611e-02  23.419  &lt; 2e-16 ***\nAge          3.597e-03  2.446e-04  14.710  &lt; 2e-16 ***\nGenderMALE  -1.583e-02  8.859e-03  -1.787   0.0739 .  \nUtil_B       3.715e-02  2.053e-03  18.097  &lt; 2e-16 ***\nUtil_D      -1.455e-02  2.578e-03  -5.644 1.69e-08 ***\nComorb_A1    4.302e-01  1.651e-02  26.062  &lt; 2e-16 ***\nLab_A        9.902e-05  2.243e-05   4.415 1.02e-05 ***\nVital_A      2.180e-03  2.597e-04   8.392  &lt; 2e-16 ***\nVital_E     -1.132e-03  1.746e-04  -6.482 9.37e-11 ***\nVital_F     -5.443e-03  1.254e-03  -4.341 1.43e-05 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 0.524 on 13990 degrees of freedom\nMultiple R-squared:  0.09236,   Adjusted R-squared:  0.09178 \nF-statistic: 158.2 on 9 and 13990 DF,  p-value: &lt; 2.2e-16\n\n# Variables selected:\n(x_back &lt;- setdiff(names(m_back$model), \"label\"))\n\n[1] \"Age\"      \"Gender\"   \"Util_B\"   \"Util_D\"   \"Comorb_A\" \"Lab_A\"    \"Vital_A\" \n[8] \"Vital_E\"  \"Vital_F\" \n\n\n\nShapleyVIC-assisted backward selection developed a more parsimonious model (with 5 variables) than conventional backward selection (with 9 variables) without significantly impairing performance.\n\n\ncompute_mse &lt;- function(y, y_pred) {\n  mean((y - y_pred) ^ 2)\n}\n# Mean squared error (MSE) of the two models on test set:\nc(ShapleyVIC_assisted_backward_selection = compute_mse(\n  y = test_set$label, y_pred = predict(m_svic, newdata = test_set)),\n  Conventional_backward_selection = compute_mse(\n  y = test_set$label, y_pred = predict(m_back, newdata = test_set))\n)\n\nShapleyVIC_assisted_backward_selection        Conventional_backward_selection \n                             0.2743280                              0.2722482"
  }
]