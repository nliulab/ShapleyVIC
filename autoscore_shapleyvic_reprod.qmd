# AutoScore-ShapleyVIC Reproducible Example

```{r, include=FALSE}
knitr::opts_chunk$set(cache = TRUE)
```

This chapter provides a fully reproducible example to demonstrate in detail the 
use of the AutoScore-ShapleyVIC workflow, using a simulated dataset with binary outcome available from the AutoScore package. The data is described in detail in 
the [AutoScore Guidebook](https://nliulab.github.io/AutoScore/02-desc_analysis.html).

## [R] Prepare data

**This part of the workflow is implemented in R.**

### Load data

- Load `sample_data` from the AutoScore package.
- As required by AutoScore, change the name of outcome variable to `label`.
- Read 
[AutoScore Guidebook](https://nliulab.github.io/AutoScore/03-data_processing.html) 
for detailed data requirement.

```{r, warning=TRUE, message=TRUE}
library(AutoScore)
data("sample_data")
names(sample_data)[names(sample_data) == "Mortality_inpatient"] <- "label"
check_data(sample_data)
dim(sample_data)
```

- As required by ShapleyVIC, code the binary outcome as 0/1.
- All variables are continuous.

```{r}
sample_data$label <- as.numeric(sample_data$label == "TRUE")
head(sample_data)
```

### Prepare training, validation, and test datasets

- Given large sample size (n=`r nrow(sample_data)`), split the data into 
training (70%), validation (10%) and test (20%) sets for risk score development.

```{r}
set.seed(4)
out_split <- split_data(data = sample_data, ratio = c(0.7, 0.1, 0.2))
train_set <- out_split$train_set
dim(train_set)
validation_set <- out_split$validation_set
dim(validation_set)
test_set <- out_split$test_set
dim(test_set)
```

- Prepare `output_dir` for ShapleyVIC, using `train_set` as training set and 
`validation_set` as the explanation data. 

:::callout-important
- *As detailed in [Chapter 1](data.qmd), check for and handle data issues before applying ShapleyVIC.*
- *This demo uses data as-is because it is simulated clean data.*
:::

```{r}
output_dir <- "mort_output"
if (!dir.exists(output_dir)) dir.create(output_dir)
write.csv(train_set, file = file.path(output_dir, "train_set.csv"), 
          row.names = FALSE)
write.csv(validation_set, 
          file = file.path(output_dir, "validation_set.csv"), 
          row.names = FALSE)
```

## [Python] Compute ShapleyVIC values

**This part of the workflow is implemented in Python.**

- Load data and set up input information.

```{python, eval=FALSE}
import os
import pandas as pd
output_dir = "mort_output"
dat_train = pd.read_csv(os.path.join(output_dir, 'train_set.csv'))
dat_expl = pd.read_csv(os.path.join(output_dir, 'validation_set.csv'))

y_name = 'label'
from ShapleyVIC import model
model_object = model.models(
    x=dat_train.drop(columns=[y_name]), y=dat_train[y_name], 
    # No need to specify x_names_cat because all variables are continuous
    outcome_type="binary", output_dir=output_dir
)
```

- Set values for hyper-parameters `u1` and `u2`.

```{python, eval=FALSE}
u1, u2 = model_object.init_hyper_params(m=200)
(u1, u2)
```

```
(0.5, 15.625)
```

- Draw 250 nearly optimal models from 500 initial samples.

```{python, eval=FALSE}
model_object.draw_models(u1=u1, u2=u2, m=500, n_final=250, random_state=1234)
model_object.models_plot
```

::: {.figure style="text-align: center"}
<img src="mort_output/output.png" width="70%"/>
:::

::: {.figure style="text-align: center"}
<img src="mort_output/output2.png" width="70%"/>
:::

- Compute ShapleyVIC values.

```{python, eval=FALSE}
from ShapleyVIC import compute
m_svic = compute.compute_shapley_vic(
    model_obj=model_object, 
    x_expl=dat_expl.drop(columns=[y_name]), y_expl=dat_expl[y_name], 
    n_cores=25, # running on a PC with 40 logical processors
    threshold=0.05
)
```

::: callout-note
- *For users' reference, the command above took approximately 17 hours on a PC (Windows 10 Education; Intel(R) Xeon(R) Silver 4210 CPU @ 2.20GHz 2.19GHz (2 processors); 128GB RAM).*
:::

## [R] Develop risk score 

**This part of the workflow is implemented in R.**

### Rank variables using ShapleyVIC

- Compile ShapleyVIC output.

```{r}
library(ShapleyVIC)
model_object <- compile_shapley_vic(
  output_dir = output_dir, outcome_type = "binary"
)
```

- Visualize ShapleyVIC values for overall variable importance.

```{r}
model_plots <- plot(model_object)
```

- Derive ShapleyVIC-based ensemble variable ranking.

```{r}
ranking <- rank_variables(model_object, summarise = TRUE, as_vector = TRUE)
ranking
```

### Develop risk score using AutoScore workflow

- Based on the ensemble variable ranking, apply [AutoScore STEP(ii)](https://nliulab.github.io/AutoScore/04-autoscore.html#stepii-select-variables-with-parsimony-plot) to select the best model with parsimony plot.

```{r, fig.width=7, fig.height=5}
AUC <- AutoScore_parsimony(
  train_set = train_set, validation_set = validation_set, 
  rank = ranking, max_score = 100, n_min = 1, n_max = length(ranking)
)
```

- This parsimony is somewhat smoother than [that from random forest-based variable ranking used in AutoScore](https://nliulab.github.io/AutoScore/04-autoscore.html#stepii-select-variables-with-parsimony-plot).
- A feasible choice is to select the top 6 variables, as adding additional 
variables does not substantially improve model performance.
- Apply [AutoScore STEP(iii)](https://nliulab.github.io/AutoScore/04-autoscore.html#model) to build initial scores from the top 6 variables.

```{r, fig.width=5, fig.height=5}
cut_vec <- AutoScore_weighting(
  train_set = train_set, validation_set = validation_set, 
  final_variables = names(ranking)[1:6], max_score = 100
)
```

- Users can apply [additional AutoScore STEPs](https://nliulab.github.io/AutoScore/04-autoscore.html#stepiv-fine-tune-initial-score-from-stepiii) for subsequent model fine-tuning and evaluation.
